# robots.txt for D&S Partners

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://yourdomain.com/sitemap.xml

# Disallow crawling of API routes and admin areas (if any)
Disallow: /api/
Disallow: /_next/
Disallow: /admin/

# Allow important pages for SEO
Allow: /
Allow: /feedback

# Crawl-delay (optional, can help with server load)
Crawl-delay: 1